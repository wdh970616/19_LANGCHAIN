{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM As Judge\n",
    "* LLM 모델을 평가자로 설정하여 모델의 성능을 평가하고 개선할 수 있다.\n",
    "\n",
    "### OFF the shelf Evaluator\n",
    "* LangSmith에서 제공하는 기본 평가자 LLM을 사용하여 모델의 출력을 자동으로 평가할 수 있게 된다.\n",
    "\n",
    "**주요 특징**\n",
    "* 사전 정의된 평가 기준 제공\n",
    "* 일관된 평가 방식 적용\n",
    "* 대규모 출력 평가 자동화 가능\n",
    "\n",
    "**필요 정보**\n",
    "* input : 질문, 보통 데이터셋의 Question이 사용된다.\n",
    "* prection : LLM이 생성한 답변\n",
    "* reference : 정답 답변, Context 등 변칙적으로 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'백설공주는 사과를 먹고 쓰러졌습니다.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "rag = PDFRAG(\n",
    "    file_path=\"data/snow-white.pdf\",\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0),\n",
    ")\n",
    "\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "chain.invoke(\"백설공주는 어떤 과일을 먹고 쓰러졌나요?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
